---
layout: publication
title: Convolutional Image Captioning
authors: Jyoti Aneja, Aditya Deshpande, Alexander Schwing
conference: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition
year: 2018
bibkey: aneja2017convolutional
citations: 390
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1711.09151'}]
tags: ["CVPR", "Model Architecture"]
short_authors: Jyoti Aneja, Aditya Deshpande, Alexander Schwing
---
Image captioning is an important but challenging task, applicable to virtual
assistants, editing tools, image indexing, and support of the disabled. Its
challenges are due to the variability and ambiguity of possible image
descriptions. In recent years significant progress has been made in image
captioning, using Recurrent Neural Networks powered by long-short-term-memory
(LSTM) units. Despite mitigating the vanishing gradient problem, and despite
their compelling ability to memorize dependencies, LSTM units are complex and
inherently sequential across time. To address this issue, recent work has shown
benefits of convolutional networks for machine translation and conditional
image generation. Inspired by their success, in this paper, we develop a
convolutional image captioning technique. We demonstrate its efficacy on the
challenging MSCOCO dataset and demonstrate performance on par with the
baseline, while having a faster training time per number of parameters. We also
perform a detailed analysis, providing compelling reasons in favor of
convolutional language generation approaches.