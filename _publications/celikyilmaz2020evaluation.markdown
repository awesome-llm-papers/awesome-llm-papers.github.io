---
layout: publication
title: 'Evaluation Of Text Generation: A Survey'
authors: Asli Celikyilmaz, Elizabeth Clark, Jianfeng Gao
conference: Arxiv
year: 2020
bibkey: celikyilmaz2020evaluation
citations: 200
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2006.14799'}]
tags: ["Evaluation", "Survey Paper"]
short_authors: Asli Celikyilmaz, Elizabeth Clark, Jianfeng Gao
---
The paper surveys evaluation methods of natural language generation (NLG)
systems that have been developed in the last few years. We group NLG evaluation
methods into three categories: (1) human-centric evaluation metrics, (2)
automatic metrics that require no training, and (3) machine-learned metrics.
For each category, we discuss the progress that has been made and the
challenges still being faced, with a focus on the evaluation of recently
proposed NLG tasks and neural NLG models. We then present two examples for
task-specific NLG evaluations for automatic text summarization and long text
generation, and conclude the paper by proposing future research directions.