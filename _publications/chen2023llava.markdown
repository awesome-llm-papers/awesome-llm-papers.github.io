---
layout: publication
title: 'Llava-interactive: An All-in-one Demo For Image Chat, Segmentation, Generation
  And Editing'
authors: Wei-ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, Chunyuan Li
conference: No Venue
year: 2023
bibkey: chen2023llava
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2311.00571'}]
tags: ["Dialogue & Multi Turn", "Prompting", "Training Techniques"]
short_authors: Chen et al.
---
LLaVA-Interactive is a research prototype for multimodal human-AI interaction. The system can have multi-turn dialogues with human users by taking multimodal user inputs and generating multimodal responses. Importantly, LLaVA-Interactive goes beyond language prompt, where visual prompt is enabled to align human intents in the interaction. The development of LLaVA-Interactive is extremely cost-efficient as the system combines three multimodal skills of pre-built AI models without additional model training: visual chat of LLaVA, image segmentation from SEEM, as well as image generation and editing from GLIGEN. A diverse set of application scenarios is presented to demonstrate the promises of LLaVA-Interactive and to inspire future research in multimodal interactive systems.

https://huggingface.co/discussions/paper/65430d63d292675f292f61ed