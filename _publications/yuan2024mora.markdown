---
layout: publication
title: 'Mora: Enabling Generalist Video Generation Via A Multi-agent Framework'
authors: Zhengqing Yuan, Ruoxi Chen, Zhaoxu Li, Haolong Jia, Lifang He, Chi Wang,
  Lichao Sun
conference: No Venue
year: 2024
bibkey: yuan2024mora
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2403.13248'}]
tags: ["Agentic"]
short_authors: Yuan et al.
---
Sora is the first large-scale generalist video generation model that garnered significant attention across society. Since its launch by OpenAI in February 2024, no other video generation models have paralleled \{Sora\}'s performance or its capacity to support a broad spectrum of video generation tasks. Additionally, there are only a few fully published video generation models, with the majority being closed-source. To address this gap, this paper proposes a new multi-agent framework Mora, which incorporates several advanced visual AI agents to replicate generalist video generation demonstrated by Sora. In particular, Mora can utilize multiple visual agents and successfully mimic Sora's video generation capabilities in various tasks, such as (1) text-to-video generation, (2) text-conditional image-to-video generation, (3) extend generated videos, (4) video-to-video editing, (5) connect videos and (6) simulate digital worlds. Our extensive experimental results show that Mora achieves performance that is proximate to that of Sora in various tasks. However, there exists an obvious performance gap between our work and Sora when assessed holistically. In summary, we hope this project can guide the future trajectory of video generation through collaborative AI agents.

https://huggingface.co/discussions/paper/65fb8f08a12d7b72305fabb5