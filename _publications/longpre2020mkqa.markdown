---
layout: publication
title: 'MKQA: A Linguistically Diverse Benchmark For Multilingual Open Domain Question
  Answering'
authors: Shayne Longpre, Yi Lu, Joachim Daiber
conference: Transactions of the Association for Computational Linguistics
year: 2021
bibkey: longpre2020mkqa
citations: 94
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2007.15207'}]
tags: ["Datasets", "Evaluation", "TACL"]
short_authors: Shayne Longpre, Yi Lu, Joachim Daiber
---
Progress in cross-lingual modeling depends on challenging, realistic, and
diverse evaluation sets. We introduce Multilingual Knowledge Questions and
Answers (MKQA), an open-domain question answering evaluation set comprising 10k
question-answer pairs aligned across 26 typologically diverse languages (260k
question-answer pairs in total). Answers are based on a heavily curated,
language-independent data representation, making results comparable across
languages and independent of language-specific passages. With 26 languages,
this dataset supplies the widest range of languages to-date for evaluating
question answering. We benchmark a variety of state-of-the-art methods and
baselines for generative and extractive question answering, trained on Natural
Questions, in zero shot and translation settings. Results indicate this dataset
is challenging even in English, but especially in low-resource languages