---
layout: publication
title: Aria Everyday Activities Dataset
authors: Zhaoyang Lv, Nickolas Charron, Pierre Moulon, Alexander Gamino, Cheng Peng,
  Chris Sweeney, Edward Miller, Huixuan Tang, Jeff Meissner, Jing Dong, Kiran Somasundaram,
  Luis Pesqueira, Mark Schwesinger, Omkar Parkhi, Qiao Gu, Renzo de Nardi, Shangyi
  Cheng, Steve Saarinen, Vijay Baiyya, Yuyang Zou, Richard Newcombe, Jakob Julian
  Engel, Xiaqing Pan, Carl Ren
conference: No Venue
year: 2024
bibkey: lv2024aria
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2402.13349'}]
tags: ["Datasets"]
short_authors: Lv et al.
---
We present Aria Everyday Activities (AEA) Dataset, an egocentric multimodal open dataset recorded using Project Aria glasses. AEA contains 143 daily activity sequences recorded by multiple wearers in five geographically diverse indoor locations. Each of the recording contains multimodal sensor data recorded through the Project Aria glasses. In addition, AEA provides machine perception data including high frequency globally aligned 3D trajectories, scene point cloud, per-frame 3D eye gaze vector and time aligned speech transcription. In this paper, we demonstrate a few exemplar research applications enabled by this dataset, including neural scene reconstruction and prompted segmentation. AEA is an open source dataset that can be downloaded from projectaria.com. We are also providing open-source implementations and examples of how to use the dataset in Project Aria Tools.

https://huggingface.co/discussions/paper/65d6baea6a36b5b354daef10