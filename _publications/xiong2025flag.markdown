---
layout: publication
title: 'Flag-trader: Fusion Llm-agent With Gradient-based Reinforcement Learning For
  Financial Trading'
authors: Guojun Xiong, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu,
  Xueqing Peng, Mingquan Lin, Kaleb E Smith, Xiao-yang Liu, Jimin Huang, Sophia Ananiadou,
  Qianqian Xie
conference: No Venue
year: 2025
bibkey: xiong2025flag
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2502.11433'}]
tags: ["Agentic", "Fine-Tuning", "Model Architecture", "Reinforcement Learning", "Tools"]
short_authors: Xiong et al.
---
Large language models (LLMs) fine-tuned on multimodal financial data have demonstrated impressive reasoning capabilities in various financial tasks. However, they often struggle with multi-step, goal-oriented scenarios in interactive financial markets, such as trading, where complex agentic approaches are required to improve decision-making. To address this, we propose FLAG-Trader, a unified architecture integrating linguistic processing (via LLMs) with gradient-driven reinforcement learning (RL) policy optimization, in which a partially fine-tuned LLM acts as the policy network, leveraging pre-trained knowledge while adapting to the financial domain through parameter-efficient fine-tuning. Through policy gradient optimization driven by trading rewards, our framework not only enhances LLM performance in trading but also improves results on other financial-domain tasks. We present extensive empirical evidence to validate these enhancements.

https://huggingface.co/discussions/paper/67b54a654508bd0617598c7e