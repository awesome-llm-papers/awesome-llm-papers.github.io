---
layout: publication
title: 'Goku: Flow Based Video Generative Foundation Models'
authors: Shoufa Chen, Chongjian Ge, Yuqi Zhang, Yida Zhang, Fengda Zhu, Hao Yang,
  Hongxiang Hao, Hui Wu, Zhichao Lai, Yifei Hu, Ting-che Lin, Shilong Zhang, Fu Li,
  Chuan Li, Xing Wang, Yanghua Peng, Peize Sun, Ping Luo, Yi Jiang, Zehuan Yuan, Bingyue
  Peng, Xiaobing Liu
conference: No Venue
year: 2025
bibkey: chen2025goku
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2502.04896'}]
tags: ["Model Architecture", "Training Techniques"]
short_authors: Chen et al.
---
This paper introduces Goku, a state-of-the-art family of joint image-and-video generation models leveraging rectified flow Transformers to achieve industry-leading performance. We detail the foundational elements enabling high-quality visual generation, including the data curation pipeline, model architecture design, flow formulation, and advanced infrastructure for efficient and robust large-scale training. The Goku models demonstrate superior performance in both qualitative and quantitative evaluations, setting new benchmarks across major tasks. Specifically, Goku achieves 0.76 on GenEval and 83.65 on DPG-Bench for text-to-image generation, and 84.85 on VBench for text-to-video tasks. We believe that this work provides valuable insights and practical advancements for the research community in developing joint image-and-video generation models.

https://huggingface.co/discussions/paper/67a983ee9b72585dd125890f