---
layout: publication
title: 'Large Language Model For Mental Health: A Systematic Review'
authors: Zhijun Guo, Alvina Lai, Johan Hilge Thygesen, Joseph Farrington, Thomas Keen,
  Kezhi Li
conference: Proceedings of the Thirty-ThirdInternational Joint Conference on Artificial
  Intelligence
year: 2024
bibkey: guo2024large
citations: 76
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2403.15401'}]
tags: ["Applications", "IJCAI"]
short_authors: Guo et al.
---
Large language models (LLMs) have attracted significant attention for
potential applications in digital health, while their application in mental
health is subject to ongoing debate. This systematic review aims to evaluate
the usage of LLMs in mental health, focusing on their strengths and limitations
in early screening, digital interventions, and clinical applications. Adhering
to PRISMA guidelines, we searched PubMed, IEEE Xplore, Scopus, JMIR, and ACM
using keywords: 'mental health OR mental illness OR mental disorder OR
psychiatry' AND 'large language models'. We included articles published between
January 1, 2017, and April 30, 2024, excluding non-English articles. 30
articles were evaluated, which included research on mental health conditions
and suicidal ideation detection through text (n=15), usage of LLMs for mental
health conversational agents (CAs) (n=7), and other applications and
evaluations of LLMs in mental health (n=18). LLMs exhibit substantial
effectiveness in detecting mental health issues and providing accessible,
de-stigmatized eHealth services. However, the current risks associated with the
clinical use might surpass their benefits. The study identifies several
significant issues: the lack of multilingual datasets annotated by experts,
concerns about the accuracy and reliability of the content generated,
challenges in interpretability due to the 'black box' nature of LLMs, and
persistent ethical dilemmas. These include the lack of a clear ethical
framework, concerns about data privacy, and the potential for over-reliance on
LLMs by both therapists and patients, which could compromise traditional
medical practice. Despite these issues, the rapid development of LLMs
underscores their potential as new clinical aids, emphasizing the need for
continued research and development in this area.