---
layout: publication
title: 'Designing For Responsible Trust In AI Systems: A Communication Perspective'
authors: Q. Vera Liao, S. Shyam Sundar
conference: 2022 ACM Conference on Fairness Accountability and Transparency
year: 2022
bibkey: liao2022designing
citations: 80
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2204.13828'}]
tags: ["Ethics & Fairness"]
short_authors: Q. Vera Liao, S. Shyam Sundar
---
Current literature and public discourse on "trust in AI" are often focused on
the principles underlying trustworthy AI, with insufficient attention paid to
how people develop trust. Given that AI systems differ in their level of
trustworthiness, two open questions come to the fore: how should AI
trustworthiness be responsibly communicated to ensure appropriate and equitable
trust judgments by different users, and how can we protect users from deceptive
attempts to earn their trust? We draw from communication theories and
literature on trust in technologies to develop a conceptual model called MATCH,
which describes how trustworthiness is communicated in AI systems through
trustworthiness cues and how those cues are processed by people to make trust
judgments. Besides AI-generated content, we highlight transparency and
interaction as AI systems' affordances that present a wide range of
trustworthiness cues to users. By bringing to light the variety of users'
cognitive processes to make trust judgments and their potential limitations, we
urge technology creators to make conscious decisions in choosing reliable
trustworthiness cues for target users and, as an industry, to regulate this
space and prevent malicious use. Towards these goals, we define the concepts of
warranted trustworthiness cues and expensive trustworthiness cues, and propose
a checklist of requirements to help technology creators identify appropriate
cues to use. We present a hypothetical use case to illustrate how practitioners
can use MATCH to design AI systems responsibly, and discuss future directions
for research and industry efforts aimed at promoting responsible trust in AI.