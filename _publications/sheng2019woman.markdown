---
layout: publication
title: 'The Woman Worked As A Babysitter: On Biases In Language Generation'
authors: Emily Sheng, Kai-wei Chang, Premkumar Natarajan, Nanyun Peng
conference: Proceedings of the 2019 Conference on Empirical Methods in Natural Language
  Processing and the 9th International Joint Conference on Natural Language Processing
  (EMNLP-IJCNLP)
year: 2019
bibkey: sheng2019woman
citations: 374
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1909.01326'}]
tags: ["Ethics & Fairness"]
short_authors: Sheng et al.
---
We present a systematic study of biases in natural language generation (NLG)
by analyzing text generated from prompts that contain mentions of different
demographic groups. In this work, we introduce the notion of the regard towards
a demographic, use the varying levels of regard towards different demographics
as a defining metric for bias in NLG, and analyze the extent to which sentiment
scores are a relevant proxy metric for regard. To this end, we collect
strategically-generated text from language models and manually annotate the
text with both sentiment and regard scores. Additionally, we build an automatic
regard classifier through transfer learning, so that we can analyze biases in
unseen text. Together, these methods reveal the extent of the biased nature of
language model generations. Our analysis provides a study of biases in NLG,
bias metrics and correlated human judgments, and empirical evidence on the
usefulness of our annotated dataset.