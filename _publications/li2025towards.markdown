---
layout: publication
title: 'Towards Agentic RAG With Deep Reasoning: A Survey Of Rag-reasoning Systems
  In Llms'
authors: Yangning Li, Weizhi Zhang, Yuyao Yang, Wei-chieh Huang, Yaozu Wu, Junyu Luo,
  Yuanchen Bei, Henry Peng Zou, Xiao Luo, Yusheng Zhao, Chunkit Chan, Yankai Chen,
  Zhongfen Deng, Yinghui Li, Hai-tao Zheng, Dongyuan Li, Renhe Jiang, Ming Zhang,
  Yangqiu Song, Philip S. Yu
conference: No Venue
year: 2025
bibkey: li2025towards
additional_links: [{name: Code, url: 'https://github.com/DavidZWZ/Awesome-RAG-Reasoning'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2507.09477'}]
tags: ["Agentic", "RAG", "Survey Paper"]
short_authors: Li et al.
---
Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.

https://huggingface.co/discussions/paper/68787031001546c83aa4f9c2