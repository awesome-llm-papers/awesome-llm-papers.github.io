---
layout: publication
title: What Do We Want From Explainable Artificial Intelligence (XAI)? -- A Stakeholder
  Perspective On XAI And A Conceptual Model Guiding Interdisciplinary XAI Research
authors: "Markus Langer, Daniel Oster, Timo Speith, Holger Hermanns, Lena K\xE4stner,\
  \ Eva Schmidt, Andreas Sesing, Kevin Baum"
conference: Artificial Intelligence
year: 2021
bibkey: langer2021what
citations: 441
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2102.07817'}]
tags: ["Evaluation"]
short_authors: Langer et al.
---
Previous research in Explainable Artificial Intelligence (XAI) suggests that
a main aim of explainability approaches is to satisfy specific interests,
goals, expectations, needs, and demands regarding artificial systems (we call
these stakeholders' desiderata) in a variety of contexts. However, the
literature on XAI is vast, spreads out across multiple largely disconnected
disciplines, and it often remains unclear how explainability approaches are
supposed to achieve the goal of satisfying stakeholders' desiderata. This paper
discusses the main classes of stakeholders calling for explainability of
artificial systems and reviews their desiderata. We provide a model that
explicitly spells out the main concepts and relations necessary to consider and
investigate when evaluating, adjusting, choosing, and developing explainability
approaches that aim to satisfy stakeholders' desiderata. This model can serve
researchers from the variety of different disciplines involved in XAI as a
common ground. It emphasizes where there is interdisciplinary potential in the
evaluation and the development of explainability approaches.