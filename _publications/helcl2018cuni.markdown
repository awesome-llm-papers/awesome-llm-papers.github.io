---
layout: publication
title: CUNI System For The WMT18 Multimodal Translation Task
authors: "Jind\u0159ich Helcl, Jind\u0159ich Libovick\xFD, Du\u0161an Vari\u0161"
conference: 'Proceedings of the Third Conference on Machine Translation: Shared Task
  Papers'
year: 2018
bibkey: helcl2018cuni
citations: 60
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1811.04697'}]
tags: []
short_authors: "Jind\u0159ich Helcl, Jind\u0159ich Libovick\xFD, Du\u0161an Vari\u0161"
---
We present our submission to the WMT18 Multimodal Translation Task. The main
feature of our submission is applying a self-attentive network instead of a
recurrent neural network. We evaluate two methods of incorporating the visual
features in the model: first, we include the image representation as another
input to the network; second, we train the model to predict the visual features
and use it as an auxiliary objective. For our submission, we acquired both
textual and multimodal additional data. Both of the proposed methods yield
significant improvements over recurrent networks and self-attentive textual
baselines.