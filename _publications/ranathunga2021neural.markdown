---
layout: publication
title: 'Neural Machine Translation For Low-resource Languages: A Survey'
authors: Surangika Ranathunga, En-shiun Annie Lee, Marjana Prifti Skenduli, Ravi Shekhar,
  Mehreen Alam, Rishemjit Kaur
conference: ACM Computing Surveys
year: 2022
bibkey: ranathunga2021neural
citations: 171
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2106.15115'}]
tags: ["Survey Paper"]
short_authors: Ranathunga et al.
---
Neural Machine Translation (NMT) has seen a tremendous spurt of growth in
less than ten years, and has already entered a mature phase. While considered
as the most widely used solution for Machine Translation, its performance on
low-resource language pairs still remains sub-optimal compared to the
high-resource counterparts, due to the unavailability of large parallel
corpora. Therefore, the implementation of NMT techniques for low-resource
language pairs has been receiving the spotlight in the recent NMT research
arena, thus leading to a substantial amount of research reported on this topic.
This paper presents a detailed survey of research advancements in low-resource
language NMT (LRL-NMT), along with a quantitative analysis aimed at identifying
the most popular solutions. Based on our findings from reviewing previous work,
this survey paper provides a set of guidelines to select the possible NMT
technique for a given LRL data setting. It also presents a holistic view of the
LRL-NMT research landscape and provides a list of recommendations to further
enhance the research efforts on LRL-NMT.