---
layout: publication
title: 'Ufogen: You Forward Once Large Scale Text-to-image Generation Via Diffusion
  Gans'
authors: Yanwu Xu, Yang Zhao, Zhisheng Xiao, Tingbo Hou
conference: No Venue
year: 2023
bibkey: xu2023ufogen
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2311.09257'}]
tags: ["Applications", "Efficiency"]
short_authors: Xu et al.
---
Text-to-image diffusion models have demonstrated remarkable capabilities in transforming textual prompts into coherent images, yet the computational cost of their inference remains a persistent challenge. To address this issue, we present UFOGen, a novel generative model designed for ultra-fast, one-step text-to-image synthesis. In contrast to conventional approaches that focus on improving samplers or employing distillation techniques for diffusion models, UFOGen adopts a hybrid methodology, integrating diffusion models with a GAN objective. Leveraging a newly introduced diffusion-GAN objective and initialization with pre-trained diffusion models, UFOGen excels in efficiently generating high-quality images conditioned on textual descriptions in a single step. Beyond traditional text-to-image generation, UFOGen showcases versatility in applications. Notably, UFOGen stands among the pioneering models enabling one-step text-to-image generation and diverse downstream tasks, presenting a significant advancement in the landscape of efficient generative models. \blfootnote\{*Work done as a student researcher of Google, dagger indicates equal contribution.

https://huggingface.co/discussions/paper/6556e52638754a6b38fd8f42