---
layout: publication
title: Open-domain Question Answering Goes Conversational Via Question Rewriting
authors: Raviteja Anantha, Svitlana Vakulenko, Zhucheng Tu, Shayne Longpre, Stephen
  Pulman, Srinivas Chappidi
conference: 'Proceedings of the 2021 Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies'
year: 2021
bibkey: anantha2020open
citations: 92
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2010.04898'}]
tags: ["NAACL"]
short_authors: Anantha et al.
---
We introduce a new dataset for Question Rewriting in Conversational Context
(QReCC), which contains 14K conversations with 80K question-answer pairs. The
task in QReCC is to find answers to conversational questions within a
collection of 10M web pages (split into 54M passages). Answers to questions in
the same conversation may be distributed across several web pages. QReCC
provides annotations that allow us to train and evaluate individual subtasks of
question rewriting, passage retrieval and reading comprehension required for
the end-to-end conversational question answering (QA) task. We report the
effectiveness of a strong baseline approach that combines the state-of-the-art
model for question rewriting, and competitive models for open-domain QA. Our
results set the first baseline for the QReCC dataset with F1 of 19.10, compared
to the human upper bound of 75.45, indicating the difficulty of the setup and a
large room for improvement.