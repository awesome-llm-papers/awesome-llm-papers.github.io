---
layout: publication
title: 'GUI Agents: A Survey'
authors: Dang Nguyen, Jian Chen, Yu Wang, Gang Wu, Namyong Park, Zhengmian Hu, Hanjia
  Lyu, Junda Wu, Ryan Aponte, Yu Xia, Xintong Li, Jing Shi, Hongjie Chen, Viet Dac
  Lai, Zhouhang Xie, Sungchul Kim, Ruiyi Zhang, Tong Yu, Mehrab Tanjim, Nesreen K.
  Ahmed, Puneet Mathur, Seunghyun Yoon, Lina Yao, Branislav Kveton, Thien Huu Nguyen,
  Trung Bui, Tianyi Zhou, Ryan A. Rossi, Franck Dernoncourt
conference: No Venue
year: 2024
bibkey: nguyen2024gui
additional_links: [{name: Code, url: 'https://huggingface.co/discussions/paper/676389c8c998c60976a9a9aa'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2412.13501'}]
tags: ["Applications", "Survey Paper", "Tools"]
short_authors: Nguyen et al.
---
Graphical User Interface (GUI) agents, powered by Large Foundation Models, have emerged as a transformative approach to automating human-computer interaction. These agents autonomously interact with digital systems or software applications via GUIs, emulating human actions such as clicking, typing, and navigating visual elements across diverse platforms. Motivated by the growing interest and fundamental importance of GUI agents, we provide a comprehensive survey that categorizes their benchmarks, evaluation metrics, architectures, and training methods. We propose a unified framework that delineates their perception, reasoning, planning, and acting capabilities. Furthermore, we identify important open challenges and discuss key future directions. Finally, this work serves as a basis for practitioners and researchers to gain an intuitive understanding of current progress, techniques, benchmarks, and critical open problems that remain to be addressed.

https://huggingface.co/discussions/paper/676389c8c998c60976a9a9aa