---
layout: publication
title: 'OCNLI: Original Chinese Natural Language Inference'
authors: Hai Hu, Kyle Richardson, Liang Xu, Lu Li, Sandra Kuebler, Lawrence S. Moss
conference: 'Findings of the Association for Computational Linguistics: EMNLP 2020'
year: 2020
bibkey: hu2020ocnli
citations: 72
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2010.05444'}]
tags: ["Datasets", "EMNLP"]
short_authors: Hu et al.
---
Despite the tremendous recent progress on natural language inference (NLI),
driven largely by large-scale investment in new datasets (e.g., SNLI, MNLI) and
advances in modeling, most progress has been limited to English due to a lack
of reliable datasets for most of the world's languages. In this paper, we
present the first large-scale NLI dataset (consisting of ~56,000 annotated
sentence pairs) for Chinese called the Original Chinese Natural Language
Inference dataset (OCNLI). Unlike recent attempts at extending NLI to other
languages, our dataset does not rely on any automatic translation or non-expert
annotation. Instead, we elicit annotations from native speakers specializing in
linguistics. We follow closely the annotation protocol used for MNLI, but
create new strategies for eliciting diverse hypotheses. We establish several
baseline results on our dataset using state-of-the-art pre-trained models for
Chinese, and find even the best performing models to be far outpaced by human
performance (~12% absolute performance gap), making it a challenging new
resource that we hope will help to accelerate progress in Chinese NLU. To the
best of our knowledge, this is the first human-elicited MNLI-style corpus for a
non-English language.