---
layout: publication
title: Pegasus-v1 Technical Report
authors: Raehyuk Jung, Hyojun Go, Jaehyuk Yi, Jiho Jang, Daniel Kim, Jay Suh, Aiden
  Lee, Cooper Han, Jae Lee, Jeff Kim, Jin-young Kim, Junwan Kim, Kyle Park, Lucas
  Lee, Mars Ha, Minjoon Seo, Abraham Jo, Ed Park, Hassan Kianinejad, Sj Kim, Tony
  Moon, Wade Jeong, Andrei Popescu, Esther Kim, Ek Yoon, Genie Heo, Henry Choi, Jenna
  Kang, Kevin Han, Noah Seo, Sunny Nguyen, Ryan Won, Yeonhoo Park, Anthony Giuliani,
  Dave Chung, Hans Yoon, James Le, Jenny Ahn, June Lee, Maninder Saini, Meredith Sanders,
  Soyoung Lee, Sue Kim, Travis Couture
conference: No Venue
year: 2024
bibkey: jung2024pegasus
additional_links: [{name: Code, url: 'https://huggingface.co/discussions/paper/6628678c9176f1c30505be86'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2404.14687'}]
tags: ["Model Architecture", "Training Techniques"]
short_authors: Jung et al.
---
This technical report introduces Pegasus-1, a multimodal language model specialized in video content understanding and interaction through natural language. Pegasus-1 is designed to address the unique challenges posed by video data, such as interpreting spatiotemporal information, to offer nuanced video content comprehension across various lengths. This technical report overviews Pegasus-1's architecture, training strategies, and its performance in benchmarks on video conversation, zero-shot video question answering, and video summarization. We also explore qualitative characteristics of Pegasus-1 , demonstrating its capabilities as well as its limitations, in order to provide readers a balanced view of its current state and its future direction.

https://huggingface.co/discussions/paper/6628678c9176f1c30505be86