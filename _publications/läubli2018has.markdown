---
layout: publication
title: Has Machine Translation Achieved Human Parity? A Case For Document-level Evaluation
authors: "Samuel L\xE4ubli, Rico Sennrich, Martin Volk"
conference: Proceedings of the 2018 Conference on Empirical Methods in Natural Language
  Processing
year: 2018
bibkey: "l\xE4ubli2018has"
citations: 278
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1808.07048'}]
tags: ["EMNLP", "Evaluation"]
short_authors: "Samuel L\xE4ubli, Rico Sennrich, Martin Volk"
---
Recent research suggests that neural machine translation achieves parity with
professional human translation on the WMT Chinese--English news translation
task. We empirically test this claim with alternative evaluation protocols,
contrasting the evaluation of single sentences and entire documents. In a
pairwise ranking experiment, human raters assessing adequacy and fluency show a
stronger preference for human over machine translation when evaluating
documents as compared to isolated sentences. Our findings emphasise the need to
shift towards document-level evaluation as machine translation improves to the
degree that errors which are hard or impossible to spot at the sentence-level
become decisive in discriminating quality of different translation outputs.