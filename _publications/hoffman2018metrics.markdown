---
layout: publication
title: 'Metrics For Explainable AI: Challenges And Prospects'
authors: Robert R. Hoffman, Shane T. Mueller, Gary Klein, Jordan Litman
conference: Arxiv
year: 2018
bibkey: hoffman2018metrics
citations: 350
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1812.04608'}]
tags: ["Evaluation"]
short_authors: Hoffman et al.
---
The question addressed in this paper is: If we present to a user an AI system
that explains how it works, how do we know whether the explanation works and
the user has achieved a pragmatic understanding of the AI? In other words, how
do we know that an explanainable AI system (XAI) is any good? Our focus is on
the key concepts of measurement. We discuss specific methods for evaluating:
(1) the goodness of explanations, (2) whether users are satisfied by
explanations, (3) how well users understand the AI systems, (4) how curiosity
motivates the search for explanations, (5) whether the user's trust and
reliance on the AI are appropriate, and finally, (6) how the human-XAI work
system performs. The recommendations we present derive from our integration of
extensive research literatures and our own psychometric evaluations.