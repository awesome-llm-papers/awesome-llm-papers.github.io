---
layout: publication
title: Abstractive Dialogue Summarization With Sentence-gated Modeling Optimized By
  Dialogue Acts
authors: Chih-wen Goo, Yun-nung Chen
conference: 2018 IEEE Spoken Language Technology Workshop (SLT)
year: 2018
bibkey: goo2018abstractive
citations: 109
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1809.05715'}]
tags: ["SLT"]
short_authors: Chih-wen Goo, Yun-nung Chen
---
Neural abstractive summarization has been increasingly studied, where the
prior work mainly focused on summarizing single-speaker documents (news,
scientific publications, etc). In dialogues, there are different interactions
between speakers, which are usually defined as dialogue acts. The interactive
signals may provide informative cues for better summarizing dialogues. This
paper proposes to explicitly leverage dialogue acts in a neural summarization
model, where a sentence-gated mechanism is designed for modeling the
relationship between dialogue acts and the summary. The experiments show that
our proposed model significantly improves the abstractive summarization
performance compared to the state-of-the-art baselines on AMI meeting corpus,
demonstrating the usefulness of the interactive signal provided by dialogue
acts.