---
layout: publication
title: Compact Trilinear Interaction For Visual Question Answering
authors: Tuong Do, Thanh-toan Do, Huy Tran, Erman Tjiputra, Quang D. Tran
conference: 2019 IEEE/CVF International Conference on Computer Vision (ICCV)
year: 2019
bibkey: do2019compact
citations: 64
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1909.11874'}]
tags: ["ICCV"]
short_authors: Do et al.
---
In Visual Question Answering (VQA), answers have a great correlation with
question meaning and visual contents. Thus, to selectively utilize image,
question and answer information, we propose a novel trilinear interaction model
which simultaneously learns high level associations between these three inputs.
In addition, to overcome the interaction complexity, we introduce a multimodal
tensor-based PARALIND decomposition which efficiently parameterizes trilinear
interaction between the three inputs. Moreover, knowledge distillation is first
time applied in Free-form Opened-ended VQA. It is not only for reducing the
computational cost and required memory but also for transferring knowledge from
trilinear interaction model to bilinear interaction model. The extensive
experiments on benchmarking datasets TDIUC, VQA-2.0, and Visual7W show that the
proposed compact trilinear interaction model achieves state-of-the-art results
when using a single model on all three datasets.