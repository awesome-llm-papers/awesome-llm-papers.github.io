---
layout: publication
title: Adversarial Neural Machine Translation
authors: Lijun Wu, Yingce Xia, Li Zhao, Fei Tian, Tao Qin, Jianhuang Lai, Tie-yan
  Liu
conference: Arxiv
year: 2017
bibkey: wu2017adversarial
citations: 78
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1704.06933'}]
tags: ["Model Architecture"]
short_authors: Wu et al.
---
In this paper, we study a new learning paradigm for Neural Machine
Translation (NMT). Instead of maximizing the likelihood of the human
translation as in previous works, we minimize the distinction between human
translation and the translation given by an NMT model. To achieve this goal,
inspired by the recent success of generative adversarial networks (GANs), we
employ an adversarial training architecture and name it as Adversarial-NMT. In
Adversarial-NMT, the training of the NMT model is assisted by an adversary,
which is an elaborately designed Convolutional Neural Network (CNN). The goal
of the adversary is to differentiate the translation result generated by the
NMT model from that by human. The goal of the NMT model is to produce high
quality translations so as to cheat the adversary. A policy gradient method is
leveraged to co-train the NMT model and the adversary. Experimental results on
English\\(\rightarrow\\)French and German\\(\rightarrow\\)English translation tasks
show that Adversarial-NMT can achieve significantly better translation quality
than several strong baselines.