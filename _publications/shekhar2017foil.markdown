---
layout: publication
title: FOIL It! Find One Mismatch Between Image And Language Caption
authors: Ravi Shekhar, Sandro Pezzelle, Yauhen Klimovich, Aurelie Herbelot, Moin Nabi,
  Enver Sangineto, Raffaella Bernardi
conference: 'Proceedings of the 55th Annual Meeting of the Association for Computational
  Linguistics (Volume 1: Long Papers)'
year: 2017
bibkey: shekhar2017foil
citations: 105
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1705.01359'}]
tags: ["Datasets"]
short_authors: Shekhar et al.
---
In this paper, we aim to understand whether current language and vision
(LaVi) models truly grasp the interaction between the two modalities. To this
end, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates
images with both correct and "foil" captions, that is, descriptions of the
image that are highly similar to the original ones, but contain one single
mistake ("foil word"). We show that current LaVi models fall into the traps of
this data and perform badly on three tasks: a) caption classification (correct
vs. foil); b) foil word detection; c) foil word correction. Humans, in
contrast, have near-perfect performance on those tasks. We demonstrate that
merely utilising language cues is not enough to model FOIL-COCO and that it
challenges the state-of-the-art by requiring a fine-grained understanding of
the relation between text and image.