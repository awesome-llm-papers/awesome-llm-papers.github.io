---
layout: publication
title: Discourse-aware Neural Rewards For Coherent Text Generation
authors: Antoine Bosselut, Asli Celikyilmaz, Xiaodong He, Jianfeng Gao, Po-sen Huang,
  Yejin Choi
conference: 'Proceedings of the 2018 Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies, Volume 1
  (Long Papers)'
year: 2018
bibkey: bosselut2018discourse
citations: 80
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1805.03766'}]
tags: ["NAACL", "Reinforcement Learning"]
short_authors: Bosselut et al.
---
In this paper, we investigate the use of discourse-aware rewards with
reinforcement learning to guide a model to generate long, coherent text. In
particular, we propose to learn neural rewards to model cross-sentence ordering
as a means to approximate desired discourse structure. Empirical results
demonstrate that a generator trained with the learned reward produces more
coherent and less repetitive text than models trained with cross-entropy or
with reinforcement learning with commonly used scores as rewards.