---
layout: publication
title: 'Beyond Language Models: Byte Models Are Digital World Simulators'
authors: Shangda Wu, Xu Tan, Zili Wang, Rui Wang, Xiaobing Li, Maosong Sun
conference: No Venue
year: 2024
bibkey: wu2024beyond
additional_links: [{name: Code, url: 'https://huggingface.co/discussions/paper/65e15544ae0a6579208a7063'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2402.19155'}]
tags: []
short_authors: Wu et al.
---
Traditional deep learning often overlooks bytes, the basic units of the digital world, where all forms of information and operations are encoded and manipulated in binary format. Inspired by the success of next token prediction in natural language processing, we introduce bGPT, a model with next byte prediction to simulate the digital world. bGPT matches specialized models in performance across various modalities, including text, audio, and images, and offers new possibilities for predicting, simulating, and diagnosing algorithm or hardware behaviour. It has almost flawlessly replicated the process of converting symbolic music data, achieving a low error rate of 0.0011 bits per byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates exceptional capabilities in simulating CPU behaviour, with an accuracy exceeding 99.99% in executing various operations. Leveraging next byte prediction, models like bGPT can directly learn from vast binary data, effectively simulating the intricate patterns of the digital world.

https://huggingface.co/discussions/paper/65e15544ae0a6579208a7063