---
layout: publication
title: 'Paligemma: A Versatile 3B VLM For Transfer'
authors: "Lucas Beyer, Andreas Steiner, Andr\xE9 Susano Pinto, Alexander Kolesnikov,\
  \ Xiao Wang, Daniel Salz, Maxim Neumann, Ibrahim Alabdulmohsin, Michael Tschannen,\
  \ Emanuele Bugliarello, Thomas Unterthiner, Daniel Keysers, Skanda Koppula, Fangyu\
  \ Liu, Adam Grycner, Alexey Gritsenko, Neil Houlsby, Manoj Kumar, Keran Rong, Julian\
  \ Eisenschlos, Rishabh Kabra, Matthias Bauer, Matko Bo\u0161njak, Xi Chen, Matthias\
  \ Minderer, Paul Voigtlaender, Ioana Bica, Ivana Balazevic, Joan Puigcerver, Pinelopi\
  \ Papalampidi, Olivier Henaff, Xi Xiong, Radu Soricut, Jeremiah Harmsen, Xiaohua\
  \ Zhai"
conference: No Venue
year: 2024
bibkey: beyer2024paligemma
additional_links: [{name: Code, url: 'https://huggingface.co/discussions/paper/668f4968f65238b10c6b1317'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2407.07726'}]
tags: []
short_authors: Beyer et al.
---
PaliGemma is an open Vision-Language Model (VLM) that is based on the SigLIP-So400m vision encoder and the Gemma-2B language model. It is trained to be a versatile and broadly knowledgeable base model that is effective to transfer. It achieves strong performance on a wide variety of open-world tasks. We evaluate PaliGemma on almost 40 diverse tasks including standard VLM benchmarks, but also more specialized tasks such as remote-sensing and segmentation.

https://huggingface.co/discussions/paper/668f4968f65238b10c6b1317