---
layout: publication
title: 'Mm-llms: Recent Advances In Multimodal Large Language Models'
authors: Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dan Su, Chenhui Chu, Dong
  Yu
conference: No Venue
year: 2024
bibkey: zhang2024mm
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2401.13601'}]
tags: ["Model Architecture", "Survey Paper", "Training Techniques"]
short_authors: Zhang et al.
---
In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Specifically, we first outline general design formulations for model architecture and training pipeline. Subsequently, we provide brief introductions of 26 existing MM-LLMs, each characterized by its specific formulations. Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this survey contributes to the ongoing advancement of the MM-LLMs domain.

https://huggingface.co/discussions/paper/65b1ea39ce74220b83156863