---
layout: publication
title: Benchmarking Natural Language Understanding Services For Building Conversational
  Agents
authors: Xingkun Liu, Arash Eshghi, Pawel Swietojanski, Verena Rieser
conference: Lecture Notes in Electrical Engineering
year: 2021
bibkey: liu2019benchmarking
citations: 117
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1903.05566'}]
tags: ["Evaluation"]
short_authors: Liu et al.
---
We have recently seen the emergence of several publicly available Natural
Language Understanding (NLU) toolkits, which map user utterances to structured,
but more abstract, Dialogue Act (DA) or Intent specifications, while making
this process accessible to the lay developer. In this paper, we present the
first wide coverage evaluation and comparison of some of the most popular NLU
services, on a large, multi-domain (21 domains) dataset of 25K user utterances
that we have collected and annotated with Intent and Entity Type specifications
and which will be released as part of this submission. The results show that on
Intent classification Watson significantly outperforms the other platforms,
namely, Dialogflow, LUIS and Rasa; though these also perform well.
Interestingly, on Entity Type recognition, Watson performs significantly worse
due to its low Precision. Again, Dialogflow, LUIS and Rasa perform well on this
task.