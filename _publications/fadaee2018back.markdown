---
layout: publication
title: Back-translation Sampling By Targeting Difficult Words In Neural Machine Translation
authors: Marzieh Fadaee, Christof Monz
conference: Proceedings of the 2018 Conference on Empirical Methods in Natural Language
  Processing
year: 2018
bibkey: fadaee2018back
citations: 82
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1808.09006'}]
tags: ["EMNLP", "Training Techniques"]
short_authors: Marzieh Fadaee, Christof Monz
---
Neural Machine Translation has achieved state-of-the-art performance for
several language pairs using a combination of parallel and synthetic data.
Synthetic data is often generated by back-translating sentences randomly
sampled from monolingual data using a reverse translation model. While
back-translation has been shown to be very effective in many cases, it is not
entirely clear why. In this work, we explore different aspects of
back-translation, and show that words with high prediction loss during training
benefit most from the addition of synthetic data. We introduce several
variations of sampling strategies targeting difficult-to-predict words using
prediction losses and frequencies of words. In addition, we also target the
contexts of difficult words and sample sentences that are similar in context.
Experimental results for the WMT news translation task show that our method
improves translation quality by up to 1.7 and 1.2 Bleu points over
back-translation using random sampling for German-English and English-German,
respectively.