---
layout: publication
title: An Empirical Study Of Language CNN For Image Captioning
authors: Jiuxiang Gu, Gang Wang, Jianfei Cai, Tsuhan Chen
conference: 2017 IEEE International Conference on Computer Vision (ICCV)
year: 2017
bibkey: gu2016empirical
citations: 145
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1612.07086'}]
tags: ["ICCV"]
short_authors: Gu et al.
---
Language Models based on recurrent neural networks have dominated recent
image caption generation tasks. In this paper, we introduce a Language CNN
model which is suitable for statistical language modeling tasks and shows
competitive performance in image captioning. In contrast to previous models
which predict next word based on one previous word and hidden state, our
language CNN is fed with all the previous words and can model the long-range
dependencies of history words, which are critical for image captioning. The
effectiveness of our approach is validated on two datasets MS COCO and
Flickr30K. Our extensive experimental results show that our method outperforms
the vanilla recurrent neural network based language models and is competitive
with the state-of-the-art methods.