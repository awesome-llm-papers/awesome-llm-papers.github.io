---
layout: publication
title: Can Language Models Handle Recursively Nested Grammatical Structures? A Case
  Study On Comparing Models And Humans
authors: Andrew Kyle Lampinen
conference: 'Findings of the Association for Computational Linguistics: EMNLP 2022'
year: 2022
bibkey: lampinen2022can
citations: 90
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2210.15303'}]
tags: ["EMNLP"]
short_authors: Andrew Kyle Lampinen
---
How should we compare the capabilities of language models (LMs) and humans? I
draw inspiration from comparative psychology to highlight some challenges. In
particular, I consider a case study: processing of recursively nested
grammatical structures. Prior work suggests that LMs cannot handle these
structures as reliably as humans can. However, the humans were provided with
instructions and training, while the LMs were evaluated zero-shot. I therefore
match the evaluation more closely. Providing large LMs with a simple prompt --
substantially less content than the human training -- allows the LMs to
consistently outperform the human results, and even to extrapolate to more
deeply nested conditions than were tested with humans. Further, reanalyzing the
prior human data suggests that the humans may not perform above chance at the
difficult structures initially. Thus, large LMs may indeed process recursively
nested grammatical structures as reliably as humans. This case study highlights
how discrepancies in the evaluation can confound comparisons of language models
and humans. I therefore reflect on the broader challenge of comparing human and
model capabilities, and highlight an important difference between evaluating
cognitive models and foundation models.