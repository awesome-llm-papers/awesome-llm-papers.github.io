---
layout: publication
title: 'Jiant: A Software Toolkit For Research On General-purpose Text Understanding
  Models'
authors: Yada Pruksachatkun, Phil Yeres, Haokun Liu, Jason Phang, Phu Mon Htut, Alex
  Wang, Ian Tenney, Samuel R. Bowman
conference: 'Proceedings of the 58th Annual Meeting of the Association for Computational
  Linguistics: System Demonstrations'
year: 2020
bibkey: pruksachatkun2020jiant
citations: 75
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2003.02249'}]
tags: ["Evaluation", "Fine-Tuning", "Model Architecture", "Training Techniques"]
short_authors: Pruksachatkun et al.
---
We introduce jiant, an open source toolkit for conducting multitask and
transfer learning experiments on English NLU tasks. jiant enables modular and
configuration-driven experimentation with state-of-the-art models and
implements a broad set of tasks for probing, transfer learning, and multitask
training experiments. jiant implements over 50 NLU tasks, including all GLUE
and SuperGLUE benchmark tasks. We demonstrate that jiant reproduces published
performance on a variety of tasks and models, including BERT and RoBERTa. jiant
is available at https://jiant.info.