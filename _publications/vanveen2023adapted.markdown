---
layout: publication
title: Adapted Large Language Models Can Outperform Medical Experts In Clinical Text
  Summarization
authors: Dave van Veen, Cara van Uden, Louis Blankemeier, Jean-benoit Delbrouck, Asad
  Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis,
  Anna Seehofnerova, Nidhi Rohatgi, Poonam Hosamani, William Collins, Neera Ahuja,
  Curtis P. Langlotz, Jason Hom, Sergios Gatidis, John Pauly, Akshay S. Chaudhari
conference: Nature Medicine
year: 2024
bibkey: vanveen2023adapted
citations: 229
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2309.07430'}]
tags: ["Evaluation"]
short_authors: Veen et al.
---
Analyzing vast textual data and summarizing key information from electronic
health records imposes a substantial burden on how clinicians allocate their
time. Although large language models (LLMs) have shown promise in natural
language processing (NLP), their effectiveness on a diverse range of clinical
summarization tasks remains unproven. In this study, we apply adaptation
methods to eight LLMs, spanning four distinct clinical summarization tasks:
radiology reports, patient questions, progress notes, and doctor-patient
dialogue. Quantitative assessments with syntactic, semantic, and conceptual NLP
metrics reveal trade-offs between models and adaptation methods. A clinical
reader study with ten physicians evaluates summary completeness, correctness,
and conciseness; in a majority of cases, summaries from our best adapted LLMs
are either equivalent (45%) or superior (36%) compared to summaries from
medical experts. The ensuing safety analysis highlights challenges faced by
both LLMs and medical experts, as we connect errors to potential medical harm
and categorize types of fabricated information. Our research provides evidence
of LLMs outperforming medical experts in clinical text summarization across
multiple tasks. This suggests that integrating LLMs into clinical workflows
could alleviate documentation burden, allowing clinicians to focus more on
patient care.