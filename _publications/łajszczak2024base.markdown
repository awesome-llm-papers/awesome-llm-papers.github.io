---
layout: publication
title: 'BASE TTS: Lessons From Building A Billion-parameter Text-to-speech Model On
  100K Hours Of Data'
authors: "Mateusz \u0141ajszczak, Guillermo C\xE1mbara, Yang Li, Fatih Beyhan, Arent\
  \ van Korlaar, Fan Yang, Arnaud Joly, \xC1lvaro Mart\xEDn-cortinas, Ammar Abbas,\
  \ Adam Michalski, Alexis Moinet, Sri Karlapati, Ewa Muszy\u0144ska, Haohan Guo,\
  \ Bartosz Putrycz, Soledad L\xF3pez Gambino, Kayeon Yoo, Elena Sokolova, Thomas\
  \ Drugman"
conference: No Venue
year: 2024
bibkey: "\u0142ajszczak2024base"
additional_links: [{name: Code, url: 'https://amazon-ltts-paper.com/'}, {name: Code,
    url: 'https://huggingface.co/discussions/paper/65cc2d6b11a80579a430d73f'}, {name: Paper,
    url: 'https://arxiv.org/abs/hf2402.08093'}]
tags: ["Model Architecture"]
short_authors: "\u0141ajszczak et al."
---
We introduce a text-to-speech (TTS) model called BASE TTS, which stands for Big Adaptive Streamable TTS with Emergent abilities. BASE TTS is the largest TTS model to-date, trained on 100K hours of public domain speech data, achieving a new state-of-the-art in speech naturalness. It deploys a 1-billion-parameter autoregressive Transformer that converts raw texts into discrete codes ("speechcodes") followed by a convolution-based decoder which converts these speechcodes into waveforms in an incremental, streamable manner. Further, our speechcodes are built using a novel speech tokenization technique that features speaker ID disentanglement and compression with byte-pair encoding. Echoing the widely-reported "emergent abilities" of large language models when trained on increasing volume of data, we show that BASE TTS variants built with 10K+ hours and 500M+ parameters begin to demonstrate natural prosody on textually complex sentences. We design and share a specialized dataset to measure these emergent abilities for text-to-speech. We showcase state-of-the-art naturalness of BASE TTS by evaluating against baselines that include publicly available large-scale text-to-speech systems: YourTTS, Bark and TortoiseTTS. Audio samples generated by the model can be heard at https://amazon-ltts-paper.com/.

https://huggingface.co/discussions/paper/65cc2d6b11a80579a430d73f