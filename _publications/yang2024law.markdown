---
layout: publication
title: Law Of Vision Representation In Mllms
authors: Shijia Yang, Bohan Zhai, Quanzeng You, Jianbo Yuan, Hongxia Yang, Chenfeng
  Xu
conference: No Venue
year: 2024
bibkey: yang2024law
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2408.16357'}]
tags: []
short_authors: Yang et al.
---
We present the "Law of Vision Representation" in multimodal large language models (MLLMs). It reveals a strong correlation between the combination of cross-modal alignment, correspondence in vision representation, and MLLM performance. We quantify the two factors using the cross-modal Alignment and Correspondence score (AC score). Through extensive experiments involving thirteen different vision representation settings and evaluations across eight benchmarks, we find that the AC score is linearly correlated to model performance. By leveraging this relationship, we are able to identify and train the optimal vision representation only, which does not require finetuning the language model every time, resulting in a 99.7% reduction in computational cost.

https://huggingface.co/discussions/paper/66d125143da2d178ceee1979