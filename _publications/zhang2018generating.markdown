---
layout: publication
title: Generating Informative And Diverse Conversational Responses Via Adversarial
  Information Maximization
authors: Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett,
  Bill Dolan
conference: Arxiv
year: 2018
bibkey: zhang2018generating
citations: 174
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1809.05972'}]
tags: ["Security", "Tools", "Training Techniques"]
short_authors: Zhang et al.
---
Responses generated by neural conversational models tend to lack
informativeness and diversity. We present Adversarial Information Maximization
(AIM), an adversarial learning strategy that addresses these two related but
distinct problems. To foster response diversity, we leverage adversarial
training that allows distributional matching of synthetic and real responses.
To improve informativeness, our framework explicitly optimizes a variational
lower bound on pairwise mutual information between query and response.
Empirical results from automatic and human evaluations demonstrate that our
methods significantly boost informativeness and diversity.