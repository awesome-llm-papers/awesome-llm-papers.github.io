---
layout: publication
title: 'Seed-music: A Unified Framework For High Quality And Controlled Music Generation'
authors: Ye Bai, Haonan Chen, Jitong Chen, Zhuo Chen, Yi Deng, Xiaohong Dong, Lamtharn
  Hantrakul, Weituo Hao, Qingqing Huang, Zhongyi Huang, Dongya Jia, Feihu La, Duc
  Le, Bochen Li, Chumin Li, Hui Li, Xingxing Li, Shouda Liu, Wei-tsung Lu, Yiqing
  Lu, Andrew Shaw, Janne Spijkervet, Yakun Sun, Bo Wang, Ju-chiang Wang, Yuping Wang,
  Yuxuan Wang, Ling Xu, Yifeng Yang, Chao Yao, Shuo Zhang, Yang Zhang, Yilin Zhang,
  Hang Zhao, Ziyi Zhao, Dejian Zhong, Shicen Zhou, Pei Zou
conference: No Venue
year: 2024
bibkey: bai2024seed
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2409.09214'}]
tags: ["Tools"]
short_authors: Bai et al.
---
We introduce Seed-Music, a suite of music generation systems capable of producing high-quality music with fine-grained style control. Our unified framework leverages both auto-regressive language modeling and diffusion approaches to support two key music creation workflows: controlled music generation and post-production editing. For controlled music generation, our system enables vocal music generation with performance controls from multi-modal inputs, including style descriptions, audio references, musical scores, and voice prompts. For post-production editing, it offers interactive tools for editing lyrics and vocal melodies directly in the generated audio. We encourage readers to listen to demo audio examples at https://team.doubao.com/seed-music .

https://huggingface.co/discussions/paper/66e8f415cd955ad711aa028e