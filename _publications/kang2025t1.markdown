---
layout: publication
title: 'T1: Tool-integrated Self-verification For Test-time Compute Scaling In Small
  Language Models'
authors: Minki Kang, Jongwon Jeong, Jaewoong Cho
conference: No Venue
year: 2025
bibkey: kang2025t1
additional_links: [{name: Code, url: 'https://huggingface.co/discussions/paper/67f48f00463c4d1c4ae52882'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2504.04718'}]
tags: ["Efficiency", "Tools"]
short_authors: Minki Kang, Jongwon Jeong, Jaewoong Cho
---
Recent studies have demonstrated that test-time compute scaling effectively improves the performance of small language models (sLMs). However, prior research has mainly examined test-time compute scaling with an additional larger model as a verifier, leaving self-verification by sLMs underexplored. In this work, we investigate whether sLMs can reliably self-verify their outputs under test-time scaling. We find that even with knowledge distillation from larger verifiers, sLMs struggle with verification tasks requiring memorization, such as numerical calculations and fact-checking. To address this limitation, we propose Tool-integrated self-verification (T1), which delegates memorization-heavy verification steps to external tools, such as a code interpreter. Our theoretical analysis shows that tool integration reduces memorization demands and improves test-time scaling performance. Experiments on the MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under test-time scaling outperforms the significantly larger Llama-3.1 8B model. Moreover, T1 generalizes effectively to both mathematical (MATH500) and multi-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the potential of tool integration to substantially improve the self-verification abilities of sLMs.

https://huggingface.co/discussions/paper/67f48f00463c4d1c4ae52882