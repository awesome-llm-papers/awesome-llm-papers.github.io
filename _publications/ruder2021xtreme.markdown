---
layout: publication
title: 'XTREME-R: Towards More Challenging And Nuanced Multilingual Evaluation'
authors: Sebastian Ruder, Noah Constant, Jan Botha, Aditya Siddhant, Orhan Firat,
  Jinlan Fu, Pengfei Liu, Junjie Hu, Dan Garrette, Graham Neubig, Melvin Johnson
conference: Proceedings of the 2021 Conference on Empirical Methods in Natural Language
  Processing
year: 2021
bibkey: ruder2021xtreme
citations: 100
additional_links: [{name: Code, url: 'https://sites.research.google/xtreme'}, {name: Code,
    url: 'https://github.com/google-research/xtreme'}, {name: Paper, url: 'https://arxiv.org/abs/2104.07412'}]
tags: ["EMNLP", "Evaluation"]
short_authors: Ruder et al.
---
Machine learning has brought striking advances in multilingual natural
language processing capabilities over the past year. For example, the latest
techniques have improved the state-of-the-art performance on the XTREME
multilingual benchmark by more than 13 points. While a sizeable gap to
human-level performance remains, improvements have been easier to achieve in
some tasks than in others. This paper analyzes the current state of
cross-lingual transfer learning and summarizes some lessons learned. In order
to catalyze meaningful progress, we extend XTREME to XTREME-R, which consists
of an improved set of ten natural language understanding tasks, including
challenging language-agnostic retrieval tasks, and covers 50 typologically
diverse languages. In addition, we provide a massively multilingual diagnostic
suite (MultiCheckList) and fine-grained multi-dataset evaluation capabilities
through an interactive public leaderboard to gain a better understanding of
such models. The leaderboard and code for XTREME-R will be made available at
https://sites.research.google/xtreme and
https://github.com/google-research/xtreme respectively.