---
layout: publication
title: Audio-visual Scene-aware Dialog
authors: Huda Alamri, Vincent Cartillier, Abhishek Das, Jue Wang, Anoop Cherian, Irfan
  Essa, Dhruv Batra, Tim K. Marks, Chiori Hori, Peter Anderson, Stefan Lee, Devi Parikh
conference: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
year: 2019
bibkey: alamri2019audio
citations: 151
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1901.09107'}]
tags: ["CVPR"]
short_authors: Alamri et al.
---
We introduce the task of scene-aware dialog. Our goal is to generate a
complete and natural response to a question about a scene, given video and
audio of the scene and the history of previous turns in the dialog. To answer
successfully, agents must ground concepts from the question in the video while
leveraging contextual cues from the dialog history. To benchmark this task, we
introduce the Audio Visual Scene-Aware Dialog (AVSD) Dataset. For each of more
than 11,000 videos of human actions from the Charades dataset, our dataset
contains a dialog about the video, plus a final summary of the video by one of
the dialog participants. We train several baseline systems for this task and
evaluate the performance of the trained models using both qualitative and
quantitative metrics. Our results indicate that models must utilize all the
available inputs (video, audio, question, and dialog history) to perform best
on this dataset.