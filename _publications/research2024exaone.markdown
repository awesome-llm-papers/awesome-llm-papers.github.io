---
layout: publication
title: 'EXAONE 3.5: Series Of Large Language Models For Real-world Use Cases'
authors: Lg Ai Research, Soyoung An, Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley
  Jungkyu Choi, Seokhee Hong, Junwon Hwang, Hyojin Jeon, Gerrard Jeongwon Jo, Hyunjik
  Jo, Jiyeon Jung, Yountae Jung, Hyosang Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim,
  Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Haeju Lee,
  Honglak Lee, Jinsik Lee, Kyungmin Lee, Woohyung Lim, Sangha Park, Sooyoun Park,
  Yongmin Park, Sihoon Yang, Heuiyeen Yeen, Hyeongu Yun
conference: No Venue
year: 2024
bibkey: research2024exaone
additional_links: [{name: Code, url: 'https://huggingface.co/LGAI-EXAONE'}, {name: Code,
    url: 'https://huggingface.co/discussions/paper/6756494bb9a4fc238b2f5dc4'}, {name: Paper,
    url: 'https://arxiv.org/abs/hf2412.04862'}]
tags: ["Applications", "Instruction Following"]
short_authors: Research et al.
---
This technical report introduces the EXAONE 3.5 instruction-tuned language models, developed and released by LG AI Research. The EXAONE 3.5 language models are offered in three configurations: 32B, 7.8B, and 2.4B. These models feature several standout capabilities: 1) exceptional instruction following capabilities in real-world scenarios, achieving the highest scores across seven benchmarks, 2) outstanding long-context comprehension, attaining the top performance in four benchmarks, and 3) competitive results compared to state-of-the-art open models of similar sizes across nine general benchmarks. The EXAONE 3.5 language models are open to anyone for research purposes and can be downloaded from https://huggingface.co/LGAI-EXAONE. For commercial use, please reach out to the official contact point of LG AI Research: contact_us@lgresearch.ai.

https://huggingface.co/discussions/paper/6756494bb9a4fc238b2f5dc4