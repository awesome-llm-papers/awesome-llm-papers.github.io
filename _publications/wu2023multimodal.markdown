---
layout: publication
title: 'Multimodal Large Language Models: A Survey'
authors: Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, Philip S. Yu
conference: 2023 IEEE International Conference on Big Data (BigData)
year: 2023
bibkey: wu2023multimodal
citations: 63
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2311.13165'}]
tags: ["Applications", "Datasets", "Survey Paper"]
short_authors: Wu et al.
---
The exploration of multimodal language models integrates multiple data types,
such as images, text, language, audio, and other heterogeneity. While the
latest large language models excel in text-based tasks, they often struggle to
understand and process other data types. Multimodal models address this
limitation by combining various modalities, enabling a more comprehensive
understanding of diverse data. This paper begins by defining the concept of
multimodal and examining the historical development of multimodal algorithms.
Furthermore, we introduce a range of multimodal products, focusing on the
efforts of major technology companies. A practical guide is provided, offering
insights into the technical aspects of multimodal models. Moreover, we present
a compilation of the latest algorithms and commonly used datasets, providing
researchers with valuable resources for experimentation and evaluation. Lastly,
we explore the applications of multimodal models and discuss the challenges
associated with their development. By addressing these aspects, this paper aims
to facilitate a deeper understanding of multimodal models and their potential
in various domains.