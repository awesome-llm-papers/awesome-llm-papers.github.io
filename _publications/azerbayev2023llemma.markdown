---
layout: publication
title: 'Llemma: An Open Language Model For Mathematics'
authors: Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen
  Mcaleer, Albert Q. Jiang, Jia Deng, Stella Biderman, Sean Welleck
conference: No Venue
year: 2023
bibkey: azerbayev2023llemma
additional_links: [{name: Code, url: 'https://huggingface.co/discussions/paper/652de6c2d2937a53ed729c11'},
  {name: Paper, url: 'https://arxiv.org/abs/hf2310.10631'}]
tags: ["Evaluation"]
short_authors: Azerbayev et al.
---
We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the MATH benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments.

https://huggingface.co/discussions/paper/652de6c2d2937a53ed729c11