---
layout: publication
title: Persistent Anti-muslim Bias In Large Language Models
authors: Abubakar Abid, Maheen Farooqi, James Zou
conference: Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society
year: 2021
bibkey: abid2021persistent
citations: 325
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2101.05783'}]
tags: ["AAAI", "Ethics & Fairness"]
short_authors: Abubakar Abid, Maheen Farooqi, James Zou
---
It has been observed that large-scale language models capture undesirable
societal biases, e.g. relating to race and gender; yet religious bias has been
relatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual
language model, captures persistent Muslim-violence bias. We probe GPT-3 in
various ways, including prompt completion, analogical reasoning, and story
generation, to understand this anti-Muslim bias, demonstrating that it appears
consistently and creatively in different uses of the model and that it is
severe even compared to biases about other religious groups. For instance,
"Muslim" is analogized to "terrorist" in 23% of test cases, while "Jewish" is
mapped to "money" in 5% of test cases. We quantify the positive distraction
needed to overcome this bias with adversarial text prompts, and find that use
of the most positive 6 adjectives reduces violent completions for "Muslims"
from 66% to 20%, but which is still higher than for other religious groups.