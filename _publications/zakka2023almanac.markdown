---
layout: publication
title: 'Almanac: Retrieval-augmented Language Models For Clinical Medicine'
authors: Cyril Zakka, Akash Chaurasia, Rohan Shad, Alex R. Dalal, Jennifer L. Kim,
  Michael Moor, Kevin Alexander, Euan Ashley, Jack Boyd, Kathleen Boyd, Karen Hirsch,
  Curt Langlotz, Joanna Nelson, William Hiesinger
conference: NEJM AI
year: 2024
bibkey: zakka2023almanac
citations: 158
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/2303.01229'}]
tags: ["Applications", "RAG", "Tools"]
short_authors: Zakka et al.
---
Large-language models have recently demonstrated impressive zero-shot
capabilities in a variety of natural language tasks such as summarization,
dialogue generation, and question-answering. Despite many promising
applications in clinical medicine, adoption of these models in real-world
settings has been largely limited by their tendency to generate incorrect and
sometimes even toxic statements. In this study, we develop Almanac, a large
language model framework augmented with retrieval capabilities for medical
guideline and treatment recommendations. Performance on a novel dataset of
clinical scenarios (n = 130) evaluated by a panel of 5 board-certified and
resident physicians demonstrates significant increases in factuality (mean of
18% at p-value < 0.05) across all specialties, with improvements in
completeness and safety. Our results demonstrate the potential for large
language models to be effective tools in the clinical decision-making process,
while also emphasizing the importance of careful testing and deployment to
mitigate their shortcomings.