---
layout: publication
title: Paraphrasing With Large Language Models
authors: Sam Witteveen, Martin Andrews
conference: Proceedings of the 3rd Workshop on Neural Generation and Translation
year: 2019
bibkey: witteveen2019paraphrasing
citations: 78
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1911.09661'}]
tags: ["Fine-Tuning", "Model Architecture"]
short_authors: Sam Witteveen, Martin Andrews
---
Recently, large language models such as GPT-2 have shown themselves to be
extremely adept at text generation and have also been able to achieve
high-quality results in many downstream NLP tasks such as text classification,
sentiment analysis and question answering with the aid of fine-tuning. We
present a useful technique for using a large language model to perform the task
of paraphrasing on a variety of texts and subjects. Our approach is
demonstrated to be capable of generating paraphrases not only at a sentence
level but also for longer spans of text such as paragraphs without needing to
break the text into smaller chunks.