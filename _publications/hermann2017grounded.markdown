---
layout: publication
title: Grounded Language Learning In A Simulated 3D World
authors: Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan Faulkner,
  Hubert Soyer, David Szepesvari, Wojciech Marian Czarnecki, Max Jaderberg, Denis
  Teplyashin, Marcus Wainwright, Chris Apps, Demis Hassabis, Phil Blunsom
conference: Arxiv
year: 2017
bibkey: hermann2017grounded
citations: 163
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1706.06551'}]
tags: ["Agentic"]
short_authors: Hermann et al.
---
We are increasingly surrounded by artificially intelligent technology that
takes decisions and executes actions on our behalf. This creates a pressing
need for general means to communicate with, instruct and guide artificial
agents, with human language the most compelling means for such communication.
To achieve this in a scalable fashion, agents must be able to relate language
to the world and to actions; that is, their understanding of language must be
grounded and embodied. However, learning grounded language is a notoriously
challenging problem in artificial intelligence research. Here we present an
agent that learns to interpret language in a simulated 3D environment where it
is rewarded for the successful execution of written instructions. Trained via a
combination of reinforcement and unsupervised learning, and beginning with
minimal prior knowledge, the agent learns to relate linguistic symbols to
emergent perceptual representations of its physical surroundings and to
pertinent sequences of actions. The agent's comprehension of language extends
beyond its prior experience, enabling it to apply familiar language to
unfamiliar situations and to interpret entirely novel instructions. Moreover,
the speed with which this agent learns new words increases as its semantic
knowledge grows. This facility for generalising and bootstrapping semantic
knowledge indicates the potential of the present approach for reconciling
ambiguous natural language with the complexity of the physical world.