---
layout: publication
title: Imagination-augmented Agents For Deep Reinforcement Learning
authors: "Th\xE9ophane Weber, S\xE9bastien Racani\xE8re, David P. Reichert, Lars Buesing,\
  \ Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom\xE8nech Badia, Oriol Vinyals,\
  \ Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David\
  \ Silver, Daan Wierstra"
conference: Arxiv
year: 2017
bibkey: weber2017imagination
citations: 182
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1707.06203'}]
tags: ["Reinforcement Learning"]
short_authors: Weber et al.
---
We introduce Imagination-Augmented Agents (I2As), a novel architecture for
deep reinforcement learning combining model-free and model-based aspects. In
contrast to most existing model-based reinforcement learning and planning
methods, which prescribe how a model should be used to arrive at a policy, I2As
learn to interpret predictions from a learned environment model to construct
implicit plans in arbitrary ways, by using the predictions as additional
context in deep policy networks. I2As show improved data efficiency,
performance, and robustness to model misspecification compared to several
baselines.