---
layout: publication
title: 'The Chosen One: Consistent Characters In Text-to-image Diffusion Models'
authors: Omri Avrahami, Amir Hertz, Yael Vinker, Moab Arar, Shlomi Fruchter, Ohad
  Fried, Daniel Cohen-or, Dani Lischinski
conference: No Venue
year: 2023
bibkey: avrahami2023chosen
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/hf2311.10093'}]
tags: ["Applications"]
short_authors: Avrahami et al.
---
Recent advances in text-to-image generation models have unlocked vast potential for visual creativity. However, these models struggle with generation of consistent characters, a crucial aspect for numerous real-world applications such as story visualization, game development asset design, advertising, and more. Current methods typically rely on multiple pre-existing images of the target character or involve labor-intensive manual processes. In this work, we propose a fully automated solution for consistent character generation, with the sole input being a text prompt. We introduce an iterative procedure that, at each stage, identifies a coherent set of images sharing a similar identity and extracts a more consistent identity from this set. Our quantitative analysis demonstrates that our method strikes a better balance between prompt alignment and identity consistency compared to the baseline methods, and these findings are reinforced by a user study. To conclude, we showcase several practical applications of our approach. Project page is available at https://omriavrahami.com/the-chosen-one

https://huggingface.co/discussions/paper/6556e6ac7be68c09617c4e76