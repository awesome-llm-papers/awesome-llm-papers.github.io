---
layout: publication
title: Zero-resource Translation With Multi-lingual Neural Machine Translation
authors: Orhan Firat, Baskaran Sankaran, Yaser Al-onaizan, Fatos T. Yarman Vural,
  Kyunghyun Cho
conference: Proceedings of the 2016 Conference on Empirical Methods in Natural Language
  Processing
year: 2016
bibkey: firat2016zero
citations: 274
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1606.04164'}]
tags: ["EMNLP"]
short_authors: Firat et al.
---
In this paper, we propose a novel finetuning algorithm for the recently
introduced multi-way, mulitlingual neural machine translate that enables
zero-resource machine translation. When used together with novel many-to-one
translation strategies, we empirically show that this finetuning algorithm
allows the multi-way, multilingual model to translate a zero-resource language
pair (1) as well as a single-pair neural translation model trained with up to
1M direct parallel sentences of the same language pair and (2) better than
pivot-based translation strategy, while keeping only one additional copy of
attention-related parameters.