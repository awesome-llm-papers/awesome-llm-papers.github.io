---
layout: publication
title: Neural Semantic Encoders
authors: Tsendsuren Munkhdalai, Hong Yu
conference: Arxiv
year: 2017
bibkey: munkhdalai2016neural
citations: 92
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1607.04315'}]
tags: ["Model Architecture"]
short_authors: Tsendsuren Munkhdalai, Hong Yu
---
We present a memory augmented neural network for natural language
understanding: Neural Semantic Encoders. NSE is equipped with a novel memory
update rule and has a variable sized encoding memory that evolves over time and
maintains the understanding of input sequences through read\}, compose and write
operations. NSE can also access multiple and shared memories. In this paper, we
demonstrated the effectiveness and the flexibility of NSE on five different
natural language tasks: natural language inference, question answering,
sentence classification, document sentiment analysis and machine translation
where NSE achieved state-of-the-art performance when evaluated on publically
available benchmarks. For example, our shared-memory model showed an
encouraging result on neural machine translation, improving an attention-based
baseline by approximately 1.0 BLEU.