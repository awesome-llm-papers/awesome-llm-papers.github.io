---
layout: publication
title: Improving Semantic Relevance For Sequence-to-sequence Learning Of Chinese Social
  Media Text Summarization
authors: Shuming Ma, Xu Sun, Jingjing Xu, Houfeng Wang, Wenjie Li, Qi Su
conference: 'Proceedings of the 55th Annual Meeting of the Association for Computational
  Linguistics (Volume 2: Short Papers)'
year: 2017
bibkey: ma2017improving
citations: 62
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1706.02459'}]
tags: ["Training Techniques"]
short_authors: Ma et al.
---
Current Chinese social media text summarization models are based on an
encoder-decoder framework. Although its generated summaries are similar to
source texts literally, they have low semantic relevance. In this work, our
goal is to improve semantic relevance between source texts and summaries for
Chinese social media summarization. We introduce a Semantic Relevance Based
neural model to encourage high semantic similarity between texts and summaries.
In our model, the source text is represented by a gated attention encoder,
while the summary representation is produced by a decoder. Besides, the
similarity score between the representations is maximized during training. Our
experiments show that the proposed model outperforms baseline systems on a
social media corpus.