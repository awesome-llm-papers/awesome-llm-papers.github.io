---
layout: publication
title: LSTM Based Conversation Models
authors: Yi Luan, Yangfeng Ji, Mari Ostendorf
conference: Arxiv
year: 2016
bibkey: luan2016lstm
citations: 60
additional_links: [{name: Paper, url: 'https://arxiv.org/abs/1603.09457'}]
tags: ["Model Architecture"]
short_authors: Yi Luan, Yangfeng Ji, Mari Ostendorf
---
In this paper, we present a conversational model that incorporates both
context and participant role for two-party conversations. Different
architectures are explored for integrating participant role and context
information into a Long Short-term Memory (LSTM) language model. The
conversational model can function as a language model or a language generation
model. Experiments on the Ubuntu Dialog Corpus show that our model can capture
multiple turn interaction between participants. The proposed method outperforms
a traditional LSTM model as measured by language model perplexity and response
ranking. Generated responses show characteristic differences between the two
participant roles.