<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Begin Web-Stat code v 7.0 -->
  <span id="wts2185292"></span>
  <script>
    var wts = document.createElement('script');
    wts.async = true;
    wts.src = 'https://app.ardalio.com/log7.js';
    document.head.appendChild(wts);
    wts.onload = function() {
      wtslog7(2185292, 2);
    };
  </script>
  <noscript>
    <a href="https://www.web-stat.com">
      <img src="https://app.ardalio.com/7/2/2185292.png" alt="Web-Stat analytics">
    </a>
  </noscript>
  <!-- End Web-Stat code v 7.0 -->

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta
    name="keywords"
    content="large language models, GPT, transformers, BERT, natural language processing, NLP, deep learning, machine learning, source code, big code, naturalness, software engineering, programming languages, fine-tuning, pretraining, autoregressive models, attention mechanisms, multi-modal models, text generation, reinforcement learning with human feedback, RLHF, GPT-3, GPT-4, ChatGPT, OpenAI, model architectures, transfer learning, LLM applications, LLM benchmarks, LLM interpretability"
  >
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <title>
    
      KGPT: Knowledge-grounded Pre-training For Data-to-text Generation &middot; Awesome LLM Papers
    
  </title>

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link
    rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"
  >

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link
    rel="search"
    href="/public/opensearchdescription.xml"
    type="application/opensearchdescription+xml"
    title="LLM-Bible"
  />

  <!-- jQuery Library -->
  <script
    src="https://code.jquery.com/jquery-3.2.1.min.js"
    integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
    crossorigin="anonymous"
  ></script>

  <!-- DataTables CSS -->
  <link
    rel="stylesheet"
    type="text/css"
    href="https://cdn.datatables.net/1.10.20/css/jquery.dataTables.css"
  >

  <!-- DataTables JS -->
  <script
    type="text/javascript"
    charset="utf8"
    src="https://cdn.datatables.net/1.10.20/js/jquery.dataTables.js"
  ></script>
</head>


  <body class="theme-base-0d layout-reverse">

    <a href='/contributing.html' class='ribbon'>Contribute to Awesome LLM Papers</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome LLM Papers
        </a>
      </h1>
      <p class="lead">A curated collection of research papers on Large Language Models (LLMs), transformers, prompting, fine-tuning, and multi-modal systems. Maintained by <a href="https://sjmoran.github.io/">Sean Moran</a>.</p>      
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/chatbot.html">Chatbot Explorer</a>
      <a class="sidebar-nav-item" href="/digest.html">E-Mail Digest</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses & Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">Contact <a href="https://sjmoran.github.io">Sean Moran</a> about this survey or website.
      <span style="font-size: 9px">
        Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
      </span></p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">KGPT: Knowledge-grounded Pre-training For Data-to-text Generation</h1>
  <h5>
  Wenhu Chen, Yu Su, Xifeng Yan, William Yang Wang. Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) 2020
  
    â€“ <span>102 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2010.02307" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=KGPT: Knowledge-grounded Pre-training For Data-to-text Generation' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=KGPT: Knowledge-grounded Pre-training For Data-to-text Generation' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Applications">Applications</a></tag>
    
      <tag><a href="/tags.html#Datasets">Datasets</a></tag>
    
      <tag><a href="/tags.html#EMNLP">EMNLP</a></tag>
    
      <tag><a href="/tags.html#Fine-Tuning">Fine-Tuning</a></tag>
    
      <tag><a href="/tags.html#Has Code">Has Code</a></tag>
    
      <tag><a href="/tags.html#Training Techniques">Training Techniques</a></tag>
    
  </p>
  <p><p>Data-to-text generation has recently attracted substantial interests due to
its wide applications. Existing methods have shown impressive performance on an
array of tasks. However, they rely on a significant amount of labeled data for
each task, which is costly to acquire and thus limits their application to new
tasks and domains. In this paper, we propose to leverage pre-training and
transfer learning to address this issue. We propose a knowledge-grounded
pre-training (KGPT), which consists of two parts, 1) a general
knowledge-grounded generation model to generate knowledge-enriched text. 2) a
pre-training paradigm on a massive knowledge-grounded text corpus crawled from
the web. The pre-trained model can be fine-tuned on various data-to-text
generation tasks to generate task-specific text. We adopt three settings,
namely fully-supervised, zero-shot, few-shot to evaluate its effectiveness.
Under the fully-supervised setting, our model can achieve remarkable gains over
the known baselines. Under zero-shot setting, our model without seeing any
examples achieves over 30 ROUGE-L on WebNLG while all other baselines fail.
Under the few-shot setting, our model only needs about one-fifteenth as many
labeled examples to achieve the same level of performance as baseline models.
These experiments consistently prove the strong generalization ability of our
proposed framework https://github.com/wenhuchen/KGPT.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/chen2020kgpt.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

    <!-- 
    <script>
      document.addEventListener('DOMContentLoaded', function () {
        let isBot = true;

        // Check for mouse movement or keyboard interaction
        document.addEventListener('mousemove', function () {
          isBot = false;
        });
        document.addEventListener('keydown', function () {
          isBot = false;
        });

        // Redirect or take action if no user interaction is detected
        setTimeout(function () {
          if (isBot) {
            // Redirect to a challenge page or show a message
            window.location.href = '/challenge-page.html'; // Update with your actual challenge page
          }
        }, 5000); // Adjust the time delay as needed
      });
    </script>
    -->
  </body>
</html>
