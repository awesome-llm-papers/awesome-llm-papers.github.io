<!DOCTYPE html>
<html lang="en-us">

  <head>
  <!-- Begin Web-Stat code v 7.0 -->
  <span id="wts2185292"></span>
  <script>
    var wts = document.createElement('script');
    wts.async = true;
    wts.src = 'https://app.ardalio.com/log7.js';
    document.head.appendChild(wts);
    wts.onload = function() {
      wtslog7(2185292, 2);
    };
  </script>
  <noscript>
    <a href="https://www.web-stat.com">
      <img src="https://app.ardalio.com/7/2/2185292.png" alt="Web-Stat analytics">
    </a>
  </noscript>
  <!-- End Web-Stat code v 7.0 -->

  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta
    name="keywords"
    content="large language models, GPT, transformers, BERT, natural language processing, NLP, deep learning, machine learning, source code, big code, naturalness, software engineering, programming languages, fine-tuning, pretraining, autoregressive models, attention mechanisms, multi-modal models, text generation, reinforcement learning with human feedback, RLHF, GPT-3, GPT-4, ChatGPT, OpenAI, model architectures, transfer learning, LLM applications, LLM benchmarks, LLM interpretability"
  >
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [["\\(","\\)"]],
        displayMath: [["\\[","\\]"]],
      },
      options: {
        processHtmlClass: "mathjax-content",
        processEscapes: true,
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <title>
    
      Attention Flows: Analyzing And Comparing Attention Mechanisms In Language Models &middot; Awesome LLM Papers
    
  </title>

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link
    rel="stylesheet"
    href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"
  >

  <!-- Icons -->
  <link rel="shortcut icon" href="/public/favicon.svg">
  <link
    rel="search"
    href="/public/opensearchdescription.xml"
    type="application/opensearchdescription+xml"
    title="LLM-Bible"
  />

  <!-- jQuery Library -->
  <script
    src="https://code.jquery.com/jquery-3.2.1.min.js"
    integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
    crossorigin="anonymous"
  ></script>

  <!-- DataTables CSS -->
  <link
    rel="stylesheet"
    type="text/css"
    href="https://cdn.datatables.net/1.10.20/css/jquery.dataTables.css"
  >

  <!-- DataTables JS -->
  <script
    type="text/javascript"
    charset="utf8"
    src="https://cdn.datatables.net/1.10.20/js/jquery.dataTables.js"
  ></script>
</head>


  <body class="theme-base-0d layout-reverse">

    <a href='/contributing.html' class='ribbon'>Contribute to Awesome LLM Papers</a>
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          Awesome LLM Papers
        </a>
      </h1>
      <p class="lead">A curated collection of research papers on Large Language Models (LLMs), transformers, prompting, fine-tuning, and multi-modal systems. Maintained by <a href="https://sjmoran.github.io/">Sean Moran</a>.</p>      
    </div>

    <nav class="sidebar-nav">
      <div class="sidebar-item">
        <p style="font-size: 12px">Search related work 
          <input type='text' id='searchTarget' size="16"/> 
          <button onClick="search();">Go</button>
        </p>
      </div>
      <a class="sidebar-nav-item" href="/papers.html">List of Papers</a>
      <a class="sidebar-nav-item" href="/tags.html">Papers by Tag</a>
      <a class="sidebar-nav-item" href="/tsne-viz.html">2D Map of Papers</a>
      <a class="sidebar-nav-item" href="/topic-viz.html">Topic Explorer</a>
      <a class="sidebar-nav-item" href="/author-viz.html">Author Explorer </a>
      <a class="sidebar-nav-item" href="/chatbot.html">Chatbot Explorer</a>
      <a class="sidebar-nav-item" href="/digest.html">E-Mail Digest</a>
      <a class="sidebar-nav-item" href="/resources.html">Resources, Courses & Events</a>
      <a class="sidebar-nav-item" href="/contributing.html">Contributing</a>
    </nav>

    <div class="sidebar-item">
      <p style="font-size: 12px">Contact <a href="https://sjmoran.github.io">Sean Moran</a> about this survey or website.
      <span style="font-size: 9px">
        Made with <a href="https://jekyllrb.com">Jekyll</a> and <a href="https://github.com/poole/hyde">Hyde</a>.
      </span></p>
    </div>
  </div>
</div>

<script>
$("#searchTarget").keydown(function (e) {	
  if (e.keyCode == 13) {
    search();
  }
});

function search() {
  try {
    ga('send', 'event', 'search', 'search', $("#searchTarget").val());
  } finally {
    window.location = "/papers.html#" + $("#searchTarget").val();
  }
}
</script>


    <div class="content container">
      <div class="page">
  <h1 class="page-title">Attention Flows: Analyzing And Comparing Attention Mechanisms In Language Models</h1>
  <h5>
  Joseph F Derose, Jiayao Wang, Matthew Berger. IEEE Transactions on Visualization and Computer Graphics 2020
  
    – <span>72 citations</span>
  
  </h5>
  <p>
    
      [<a href="https://arxiv.org/abs/2009.07053" target="_blank">Paper</a>]
    
    &nbsp;<a href='http://scholar.google.com/scholar?q=Attention Flows: Analyzing And Comparing Attention Mechanisms In Language Models' target="_blank"><img  style="display: inline; margin: 0;" src="/public/media/google-scholar.png"/></a>
    &nbsp;<a href='https://www.semanticscholar.org/search?q=Attention Flows: Analyzing And Comparing Attention Mechanisms In Language Models' target="_blank"><img style="display: inline; margin: 0;" src="/public/media/semscholar.png"/></a>
    <br/>
    
      <tag><a href="/tags.html#Fine-Tuning">Fine-Tuning</a></tag>
    
      <tag><a href="/tags.html#Model Architecture">Model Architecture</a></tag>
    
      <tag><a href="/tags.html#Training Techniques">Training Techniques</a></tag>
    
  </p>
  <p><p>Advances in language modeling have led to the development of deep
attention-based models that are performant across a wide variety of natural
language processing (NLP) problems. These language models are typified by a
pre-training process on large unlabeled text corpora and subsequently
fine-tuned for specific tasks. Although considerable work has been devoted to
understanding the attention mechanisms of pre-trained models, it is less
understood how a model’s attention mechanisms change when trained for a target
NLP task. In this paper, we propose a visual analytics approach to
understanding fine-tuning in attention-based language models. Our
visualization, Attention Flows, is designed to support users in querying,
tracing, and comparing attention within layers, across layers, and amongst
attention heads in Transformer-based language models. To help users gain
insight on how a classification decision is made, our design is centered on
depicting classification-based attention at the deepest layer and how attention
from prior layers flows throughout words in the input. Attention Flows supports
the analysis of a single model, as well as the visual comparison between
pre-trained and fine-tuned models via their similarities and differences. We
use Attention Flows to study attention mechanisms in various sentence
understanding tasks and highlight how attention evolves to address the nuances
of solving these tasks.</p>
</p>

  <h6>Similar Work</h6>
  <p>
    <ul id="relwork">

    </ul>
  </p>

 <script>  
    $(document).ready(
      function() {
        $.getJSON("/publications-metadata/derose2020attention.json", function(data) {
          num_papers = data.length;
          html = "";
          for (let i=0; i < num_papers; i++) {
              html += '<li><a href="/publications/' + data[i][0] + '">'+ data[i][1] +'</a></li>'
          }
          $("#relwork").append(html);
        });
      });
  </script>


</div>

    </div>

    <!-- 
    <script>
      document.addEventListener('DOMContentLoaded', function () {
        let isBot = true;

        // Check for mouse movement or keyboard interaction
        document.addEventListener('mousemove', function () {
          isBot = false;
        });
        document.addEventListener('keydown', function () {
          isBot = false;
        });

        // Redirect or take action if no user interaction is detected
        setTimeout(function () {
          if (isBot) {
            // Redirect to a challenge page or show a message
            window.location.href = '/challenge-page.html'; // Update with your actual challenge page
          }
        }, 5000); // Adjust the time delay as needed
      });
    </script>
    -->
  </body>
</html>
