[["jiao2019tinybert", "Tinybert: Distilling BERT For Natural Language Understanding"], ["hou2020dynabert", "Dynabert: Dynamic BERT With Adaptive Width And Depth"], ["chen2020adabert", "Adabert: Task-adaptive BERT Compression With Differentiable Neural Architecture Search"], ["zadeh2020gobo", "GOBO: Quantizing Attention-based NLP Models For Low Latency And Energy Efficient Inference"]]