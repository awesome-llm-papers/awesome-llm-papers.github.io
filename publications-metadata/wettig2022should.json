[["xiao2020ernie", "Ernie-gram: Pre-training With Explicitly N-gram Masked Language Modeling For Natural Language Understanding"], ["chen2019uniter", "UNITER: Universal Image-text Representation Learning"], ["cui2019pre", "Pre-training With Whole Word Masking For Chinese BERT"], ["li2022scaling", "Scaling Language-image Pre-training Via Masking"]]