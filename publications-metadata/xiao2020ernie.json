[["wettig2022should", "Should You Mask 15% In Masked Language Modeling?"], ["song2020mpnet", "Mpnet: Masked And Permuted Pre-training For Language Understanding"], ["voita2019bottom", "The Bottom-up Evolution Of Representations In The Transformer: A Study With Machine Translation And Language Modeling Objectives"], ["chen2019uniter", "UNITER: Universal Image-text Representation Learning"]]