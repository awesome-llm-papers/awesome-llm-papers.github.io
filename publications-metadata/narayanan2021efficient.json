[["wei2021pangu", "Pangu-\\(\u03b1\\): Large-scale Autoregressive Pretrained Chinese Language Models With Auto-parallel Computation"], ["huang2018gpipe", "Gpipe: Efficient Training Of Giant Neural Networks Using Pipeline Parallelism"], ["rajbhandari2019zero", "Zero: Memory Optimizations Toward Training Trillion Parameter Models"], ["mohammad2019megatron", "Megatron-lm: Training Multi-billion Parameter Language Models Using Model Parallelism"]]