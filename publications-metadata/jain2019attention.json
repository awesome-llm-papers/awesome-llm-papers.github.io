[["mohankumar2020towards", "Towards Transparent And Explainable Attention Models"], ["serrano2019is", "Is Attention Interpretable?"], ["bastings2020elephant", "The Elephant In The Interpretability Room: Why Use Attention As Explanation When We Have Saliency Methods?"], ["wiegreffe2019attention", "Attention Is Not Not Explanation"]]