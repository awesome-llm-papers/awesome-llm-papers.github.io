[["qi2021mind", "Mind The Style Of Text! Adversarial And Backdoor Attacks Based On Text Style Transfer"], ["wallace2019universal", "Universal Adversarial Triggers For Attacking And Analyzing NLP"], ["wallace2020concealed", "Concealed Data Poisoning Attacks On NLP Models"], ["li2018textbugger", "Textbugger: Generating Adversarial Text Against Real-world Applications"]]