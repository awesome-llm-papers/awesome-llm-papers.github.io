[["gu2020domain", "Domain-specific Language Model Pretraining For Biomedical Natural Language Processing"], ["mehri2019pretraining", "Pretraining Methods For Dialog Context Representation Learning"], ["meng2021coco", "COCO-LM: Correcting And Contrasting Text Sequences For Language Model Pretraining"], ["conneau2019unsupervised", "Unsupervised Cross-lingual Representation Learning At Scale"]]