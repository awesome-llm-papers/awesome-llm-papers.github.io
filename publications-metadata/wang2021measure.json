[["gui2021textflint", "Textflint: Unified Multilingual Robustness Evaluation Toolkit For Natural Language Processing"], ["hendrycks2020pretrained", "Pretrained Transformers Improve Out-of-distribution Robustness"], ["hendrycks2019using", "Using Pre-training Can Improve Model Robustness And Uncertainty"], ["xu2022beyond", "Beyond Preserved Accuracy: Evaluating Loyalty And Robustness Of BERT Compression"]]