[["zadeh2020gobo", "GOBO: Quantizing Attention-based NLP Models For Low Latency And Energy Efficient Inference"], ["zhou2020bert", "BERT Loses Patience: Fast And Robust Inference With Early Exit"], ["xin2020deebert", "Deebert: Dynamic Early Exiting For Accelerating BERT Inference"], ["wang2020spatten", "Spatten: Efficient Sparse Attention Architecture With Cascade Token And Head Pruning"]]