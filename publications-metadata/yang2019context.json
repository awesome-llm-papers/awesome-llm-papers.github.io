[["yang2018modeling", "Modeling Localness For Self-attention Networks"], ["wang2019r", "R-transformer: Recurrent Neural Network Enhanced Transformer"], ["cohan2019pretrained", "Pretrained Language Models For Sequential Sentence Classification"], ["dai2019transformer", "Transformer-xl: Attentive Language Models Beyond A Fixed-length Context"]]