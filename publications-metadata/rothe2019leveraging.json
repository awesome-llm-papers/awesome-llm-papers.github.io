[["linting2020mt5", "Mt5: A Massively Multilingual Pre-trained Text-to-text Transformer"], ["ainslie2023gqa", "GQA: Training Generalized Multi-query Transformer Models From Multi-head Checkpoints"], ["popel2018training", "Training Tips For The Transformer Model"], ["yang2023baichuan", "Baichuan 2: Open Large-scale Language Models"]]