[["qiao2019understanding", "Understanding The Behaviors Of BERT In Ranking"], ["nogueira2020document", "Document Ranking With A Pretrained Sequence-to-sequence Model"], ["kim2016sequence", "Sequence-level Knowledge Distillation"], ["sun2019patient", "Patient Knowledge Distillation For BERT Model Compression"]]