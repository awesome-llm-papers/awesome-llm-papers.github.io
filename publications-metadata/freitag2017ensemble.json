[["yuan2020reinforced", "Reinforced Multi-teacher Selection For Knowledge Distillation"], ["kim2016sequence", "Sequence-level Knowledge Distillation"], ["sun2019patient", "Patient Knowledge Distillation For BERT Model Compression"], ["liu2019improving", "Improving Multi-task Deep Neural Networks Via Knowledge Distillation For Natural Language Understanding"]]