[["yuan2020reinforced", "Reinforced Multi-teacher Selection For Knowledge Distillation"], ["freitag2017ensemble", "Ensemble Distillation For Neural Machine Translation"], ["sun2019patient", "Patient Knowledge Distillation For BERT Model Compression"], ["wang2020minilm", "Minilm: Deep Self-attention Distillation For Task-agnostic Compression Of Pre-trained Transformers"]]