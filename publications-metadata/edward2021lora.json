[["sung2022lst", "LST: Ladder Side-tuning For Parameter And Memory Efficient Transfer Learning"], ["he2020deberta", "Deberta: Decoding-enhanced BERT With Disentangled Attention"], ["he2021debertav3", "Debertav3: Improving Deberta Using Electra-style Pre-training With Gradient-disentangled Embedding Sharing"], ["stickland2019bert", "BERT And Pals: Projected Attention Layers For Efficient Adaptation In Multi-task Learning"]]