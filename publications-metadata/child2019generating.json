[["roy2020efficient", "Efficient Content-based Sparse Attention With Routing Transformers"], ["qiu2019blockwise", "Blockwise Self-attention For Long Document Understanding"], ["zaheer2020big", "Big Bird: Transformers For Longer Sequences"], ["zhao2019explicit", "Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection"]]