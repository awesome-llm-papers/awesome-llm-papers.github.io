[["eisenschlos2019multifit", "Multifit: Efficient Multi-lingual Language Model Fine-tuning"], ["ebrahimi2021americasnli", "Americasnli: Evaluating Zero-shot Natural Language Understanding Of Pretrained Multilingual Models In Truly Low-resource Languages"], ["pfeiffer2020unks", "Unks Everywhere: Adapting Multilingual Language Models To New Scripts"], ["chronopoulou2019embarrassingly", "An Embarrassingly Simple Approach For Transfer Learning From Pretrained Language Models"]]