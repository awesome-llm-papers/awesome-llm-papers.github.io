[["ganesh2020compressing", "Compressing Large-scale Transformer-based Models: A Case Study On BERT"], ["chen2020adabert", "Adabert: Task-adaptive BERT Compression With Differentiable Neural Architecture Search"], ["yang2021survey", "A Survey Of Knowledge Enhanced Pre-trained Models"], ["min2021recent", "Recent Advances In Natural Language Processing Via Large Pre-trained Language Models: A Survey"]]