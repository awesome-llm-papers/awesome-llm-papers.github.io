[["guo2021longt5", "Longt5: Efficient Text-to-text Transformer For Long Sequences"], ["fan2019using", "Using Local Knowledge Graph Construction To Scale Seq2seq Models To Multi-document Inputs"], ["he2020realformer", "Realformer: Transformer Likes Residual Attention"], ["wu2021fastformer", "Fastformer: Additive Attention Can Be All You Need"]]