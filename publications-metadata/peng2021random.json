[["wu2021fastformer", "Fastformer: Additive Attention Can Be All You Need"], ["wang2020linformer", "Linformer: Self-attention With Linear Complexity"], ["kitaev2020reformer", "Reformer: The Efficient Transformer"], ["albert2023mamba", "Mamba: Linear-time Sequence Modeling With Selective State Spaces"]]