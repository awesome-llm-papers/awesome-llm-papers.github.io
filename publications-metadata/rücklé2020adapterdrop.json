[["mahabadi2021parameter", "Parameter-efficient Multi-task Fine-tuning For Transformers Via Shared Hypernetworks"], ["zhang2021tip", "Tip-adapter: Training-free Clip-adapter For Better Vision-language Modeling"], ["pfeiffer2020adapterhub", "Adapterhub: A Framework For Adapting Transformers"], ["hu2023llm", "Llm-adapters: An Adapter Family For Parameter-efficient Fine-tuning Of Large Language Models"]]