[["sun2019patient", "Patient Knowledge Distillation For BERT Model Compression"], ["wang2023robustness", "On The Robustness Of Chatgpt: An Adversarial And Out-of-distribution Perspective"], ["hendrycks2020pretrained", "Pretrained Transformers Improve Out-of-distribution Robustness"], ["yuan2020reinforced", "Reinforced Multi-teacher Selection For Knowledge Distillation"]]