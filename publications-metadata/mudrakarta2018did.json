[["hao2020self", "Self-attention Attribution: Interpreting Information Interactions Inside Transformer"], ["li2020bert", "BERT-ATTACK: Adversarial Attack Against BERT Using BERT"], ["nan2021fetaqa", "Fetaqa: Free-form Table Question Answering"], ["xu2017fooling", "Fooling Vision And Language Models Despite Localization And Attention Mechanism"]]