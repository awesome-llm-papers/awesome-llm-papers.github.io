[["shazeer2017outrageously", "Outrageously Large Neural Networks: The Sparsely-gated Mixture-of-experts Layer"], ["rajbhandari2019zero", "Zero: Memory Optimizations Toward Training Trillion Parameter Models"], ["bo2023rwkv", "RWKV: Reinventing Rnns For The Transformer Era"], ["roy2020efficient", "Efficient Content-based Sparse Attention With Routing Transformers"]]