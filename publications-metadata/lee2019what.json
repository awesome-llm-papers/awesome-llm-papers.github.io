[["liu2020understanding", "Understanding And Improving Encoder Layer Fusion In Sequence-to-sequence Learning"], ["geva2020transformer", "Transformer Feed-forward Layers Are Key-value Memories"], ["dou2018exploiting", "Exploiting Deep Representations For Neural Machine Translation"], ["vig2019analyzing", "Analyzing The Structure Of Attention In A Transformer Language Model"]]