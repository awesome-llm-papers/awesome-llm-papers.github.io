[["jain2019attention", "Attention Is Not Explanation"], ["vashishth2019attention", "Attention Interpretability Across NLP Tasks"], ["mohankumar2020towards", "Towards Transparent And Explainable Attention Models"], ["bastings2020elephant", "The Elephant In The Interpretability Room: Why Use Attention As Explanation When We Have Saliency Methods?"]]