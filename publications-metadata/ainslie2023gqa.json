[["correia2019adaptively", "Adaptively Sparse Transformers"], ["michel2019are", "Are Sixteen Heads Really Better Than One?"], ["hudson2019gqa", "GQA: A New Dataset For Real-world Visual Reasoning And Compositional Question Answering"], ["raganato2020fixed", "Fixed Encoder Self-attention Patterns In Transformer-based Machine Translation"]]