[["wu2016google", "Google's Neural Machine Translation System: Bridging The Gap Between Human And Machine Translation"], ["sukhbaatar2019adaptive", "Adaptive Attention Span In Transformers"], ["nye2021show", "Show Your Work: Scratchpads For Intermediate Computation With Language Models"], ["xue2021byt5", "Byt5: Towards A Token-free Future With Pre-trained Byte-to-byte Models"]]