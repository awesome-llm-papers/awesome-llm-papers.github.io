[["kim2016multimodal", "Multimodal Residual Learning For Visual QA"], ["prakash2016neural", "Neural Paraphrase Generation With Stacked Residual LSTM Networks"], ["kitaev2020reformer", "Reformer: The Efficient Transformer"], ["he2020realformer", "Realformer: Transformer Likes Residual Attention"]]