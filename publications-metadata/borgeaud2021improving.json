[["gao2020pile", "The Pile: An 800GB Dataset Of Diverse Text For Language Modeling"], ["daniluk2017frustratingly", "Frustratingly Short Attention Spans In Neural Language Modeling"], ["kratzwald2018adaptive", "Adaptive Document Retrieval For Deep Question Answering"], ["tetko2020state", "State-of-the-art Augmented NLP Transformer Models For Direct And Single-step Retrosynthesis"]]